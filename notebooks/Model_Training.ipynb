{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Internal Evaluation (for-norm dataset)\n",
    "This notebook focuses on **training and evaluating multiple machine learning models** using the `for-norm` dataset. The dataset is splitted into **training**, **validation**, and **testing** sets.\n",
    "\n",
    "## What this notebook covers:\n",
    "- Training 5 classic ML models:\n",
    "  - Logistic Regression\n",
    "  - Naive Bayes\n",
    "  - Decision Tree\n",
    "  - Random Forest\n",
    "  - Support Vector Machine (SVM)\n",
    "- Tuning hyperparameters using the **validation set**\n",
    "- Evaluating model performance on the **internal test set**\n",
    "- Saving all tuned models and the scaler for reuse in the external evaluation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extracted features\n",
    "df_norm = pd.read_csv(\"Processed_Features/for_norm_features.csv\")\n",
    "\n",
    "# Split features and labels\n",
    "X = df_norm.drop(columns=[\"filename\", \"split\", \"label\", \"LABEL\"])\n",
    "y = df_norm[\"LABEL\"]\n",
    "\n",
    "# Create split-based datasets\n",
    "X_train = X[df_norm[\"split\"] == \"training\"]\n",
    "y_train = y[df_norm[\"split\"] == \"training\"]\n",
    "X_val = X[df_norm[\"split\"] == \"validation\"]\n",
    "y_val = y[df_norm[\"split\"] == \"validation\"]\n",
    "X_test = X[df_norm[\"split\"] == \"testing\"]\n",
    "y_test = y[df_norm[\"split\"] == \"testing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models and grid parameters\n",
    "models = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"params\": {\"C\": [0.1, 1, 10]}\n",
    "    },\n",
    "    \"NaiveBayes\": {\n",
    "        \"model\": GaussianNB(),\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        \"model\": DecisionTreeClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [10, 20, None],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "            \"min_samples_leaf\": [1, 2]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100],\n",
    "            \"max_depth\": [10, 20, None]\n",
    "        }\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"model\": SVC(probability=True, random_state=42),\n",
    "        \"params\": {\"C\": [0.1, 1], \"kernel\": [\"linear\", \"rbf\"]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afunction to extract metrics from the classification report\n",
    "def get_metrics(y_true, y_pred, dataset_name, model_name):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Dataset\": dataset_name,\n",
    "        \"Precision_0\": report['0']['precision'],\n",
    "        \"Recall_0\": report['0']['recall'],\n",
    "        \"F1_0\": report['0']['f1-score'],\n",
    "        \"Support_0\": report['0']['support'],\n",
    "        \"Precision_1\": report['1']['precision'],\n",
    "        \"Recall_1\": report['1']['recall'],\n",
    "        \"F1_1\": report['1']['f1-score'],\n",
    "        \"Support_1\": report['1']['support'],\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tuning LogisticRegression...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tuning NaiveBayes...\n",
      "\n",
      " Tuning DecisionTree...\n",
      "\n",
      " Tuning RandomForest...\n",
      "\n",
      " Tuning SVM...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>Support_0</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>F1_1</th>\n",
       "      <th>Support_1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.851337</td>\n",
       "      <td>0.861430</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>5398.0</td>\n",
       "      <td>0.859820</td>\n",
       "      <td>0.849630</td>\n",
       "      <td>0.854694</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>0.855529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Internal Test</td>\n",
       "      <td>0.658418</td>\n",
       "      <td>0.572574</td>\n",
       "      <td>0.612503</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>0.606296</td>\n",
       "      <td>0.689046</td>\n",
       "      <td>0.645028</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>0.629478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.782921</td>\n",
       "      <td>0.867914</td>\n",
       "      <td>0.823230</td>\n",
       "      <td>5398.0</td>\n",
       "      <td>0.851890</td>\n",
       "      <td>0.759444</td>\n",
       "      <td>0.803015</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>0.813669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>Internal Test</td>\n",
       "      <td>0.600682</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.740944</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>0.903659</td>\n",
       "      <td>0.327297</td>\n",
       "      <td>0.480545</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>0.654294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.950147</td>\n",
       "      <td>0.960356</td>\n",
       "      <td>0.955224</td>\n",
       "      <td>5398.0</td>\n",
       "      <td>0.959940</td>\n",
       "      <td>0.949630</td>\n",
       "      <td>0.954757</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>0.954992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>Internal Test</td>\n",
       "      <td>0.827723</td>\n",
       "      <td>0.705485</td>\n",
       "      <td>0.761731</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>0.732976</td>\n",
       "      <td>0.846290</td>\n",
       "      <td>0.785568</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>0.774277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.991116</td>\n",
       "      <td>0.992034</td>\n",
       "      <td>0.991575</td>\n",
       "      <td>5398.0</td>\n",
       "      <td>0.992030</td>\n",
       "      <td>0.991111</td>\n",
       "      <td>0.991570</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>0.991573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Internal Test</td>\n",
       "      <td>0.922782</td>\n",
       "      <td>0.610127</td>\n",
       "      <td>0.734569</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>0.698728</td>\n",
       "      <td>0.946555</td>\n",
       "      <td>0.803977</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>0.774493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.996119</td>\n",
       "      <td>0.998518</td>\n",
       "      <td>0.997317</td>\n",
       "      <td>5398.0</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>0.996111</td>\n",
       "      <td>0.997312</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>0.997314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Internal Test</td>\n",
       "      <td>0.976274</td>\n",
       "      <td>0.468776</td>\n",
       "      <td>0.633409</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>0.639874</td>\n",
       "      <td>0.988074</td>\n",
       "      <td>0.776736</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>0.722486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model        Dataset  Precision_0  Recall_0      F1_0  \\\n",
       "0  LogisticRegression     Validation     0.851337  0.861430  0.856354   \n",
       "1  LogisticRegression  Internal Test     0.658418  0.572574  0.612503   \n",
       "2          NaiveBayes     Validation     0.782921  0.867914  0.823230   \n",
       "3          NaiveBayes  Internal Test     0.600682  0.966667  0.740944   \n",
       "4        DecisionTree     Validation     0.950147  0.960356  0.955224   \n",
       "5        DecisionTree  Internal Test     0.827723  0.705485  0.761731   \n",
       "6        RandomForest     Validation     0.991116  0.992034  0.991575   \n",
       "7        RandomForest  Internal Test     0.922782  0.610127  0.734569   \n",
       "8                 SVM     Validation     0.996119  0.998518  0.997317   \n",
       "9                 SVM  Internal Test     0.976274  0.468776  0.633409   \n",
       "\n",
       "   Support_0  Precision_1  Recall_1      F1_1  Support_1  Accuracy  \n",
       "0     5398.0     0.859820  0.849630  0.854694     5400.0  0.855529  \n",
       "1     2370.0     0.606296  0.689046  0.645028     2264.0  0.629478  \n",
       "2     5398.0     0.851890  0.759444  0.803015     5400.0  0.813669  \n",
       "3     2370.0     0.903659  0.327297  0.480545     2264.0  0.654294  \n",
       "4     5398.0     0.959940  0.949630  0.954757     5400.0  0.954992  \n",
       "5     2370.0     0.732976  0.846290  0.785568     2264.0  0.774277  \n",
       "6     5398.0     0.992030  0.991111  0.991570     5400.0  0.991573  \n",
       "7     2370.0     0.698728  0.946555  0.803977     2264.0  0.774493  \n",
       "8     5398.0     0.998515  0.996111  0.997312     5400.0  0.997314  \n",
       "9     2370.0     0.639874  0.988074  0.776736     2264.0  0.722486  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "best_models = {}\n",
    "validation_scores = []\n",
    "\n",
    "for model_name, config in models.items():\n",
    "    print(f\"\\n Tuning {model_name}...\")\n",
    "    best_f1 = -1\n",
    "    best_model = None\n",
    "\n",
    "    for params in ParameterGrid(config[\"params\"]):\n",
    "        model = clone(config[\"model\"]).set_params(**params)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        val_pred = model.predict(X_val_scaled)\n",
    "        val_f1 = f1_score(y_val, val_pred, pos_label=0)\n",
    "\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model = model\n",
    "\n",
    "    best_models[model_name] = best_model\n",
    "    val_pred = best_model.predict(X_val_scaled)\n",
    "    test_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "    results.append(get_metrics(y_val, val_pred, \"Validation\", model_name))\n",
    "    results.append(get_metrics(y_test, test_pred, \"Internal Test\", model_name))\n",
    "\n",
    "    validation_scores.append((model_name, best_f1))\n",
    "\n",
    "# Save and view results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"for_norm_internal_training_results.csv\", index=False)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: saved_models/LogisticRegression_for_norm.joblib\n",
      "Saved: saved_models/NaiveBayes_for_norm.joblib\n",
      "Saved: saved_models/DecisionTree_for_norm.joblib\n",
      "Saved: saved_models/RandomForest_for_norm.joblib\n",
      "Saved: saved_models/SVM_for_norm.joblib\n",
      "scaler saved\n"
     ]
    }
   ],
   "source": [
    "# Create a folder to store the saved models\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "# Save each model\n",
    "for model_name, model in best_models.items():\n",
    "    filepath = f\"saved_models/{model_name}_for_norm.joblib\"\n",
    "    joblib.dump(model, filepath)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, \"saved_models/for_norm_scaler.joblib\")\n",
    "print(\"scaler saved\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
