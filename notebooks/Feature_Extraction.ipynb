{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "This notebook handles the **feature extraction** from the datasets, preparing them for model training and evaluation.\n",
    "\n",
    "## What This Notebook Does:\n",
    "- Counts Audio Files:\n",
    "    - Counts the number of audio files in each dataset and their respective splits.\n",
    "    - Provides an overview of the data distribution (fake vs real, training/validation/testing).\n",
    "- Extracts Audio Features:\n",
    "    - Extracts features such as chroma, spectral, and MFCC using Librosa.\n",
    "- Saves the features in separate CSV files for each dataset:\n",
    "    - for_norm_features.csv  (features for the FoR (for-norm) dataset).\n",
    "    - release_in_wild_features.csv  (features for the In-The-Wild dataset, which is named as release-In-The-Wild).\n",
    "- Handles Errors:\n",
    "    - Logs any errors into an error log file (error_log.txt).\n",
    "    - Ensures continuous execution even if some files fail to process.\n",
    "- Uses a progress bar (`tqdm`) for better tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (downloaded inside the data folder)\n",
    "datasets = {\n",
    "    \"for-norm\": \"data/fake_or_real_dataset/for-norm/for-norm\",\n",
    "    \"release-in-the-wild\": \"data/processed_data\"\n",
    "}\n",
    "\n",
    "# Splits for the for-norm dataset\n",
    "splits = [\"training\", \"validation\", \"testing\"]\n",
    "labels = {\"fake\": 0, \"real\": 1}\n",
    "\n",
    "# Output directory\n",
    "processed_output_dir = \"Processed_Features\"\n",
    "os.makedirs(processed_output_dir, exist_ok=True)\n",
    "\n",
    "# Error log\n",
    "error_log = \"error_log.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For-Norm Dataset File Counts:\n",
      "Training:\n",
      "  - Fake: 26927 files\n",
      "  - Real: 26941 files\n",
      "Validation:\n",
      "  - Fake: 5398 files\n",
      "  - Real: 5400 files\n",
      "Testing:\n",
      "  - Fake: 2370 files\n",
      "  - Real: 2264 files\n",
      "Total files in for-norm dataset: 69300\n",
      "\n",
      "Release-In-the-Wild Dataset File Counts:\n",
      "  - Fake: 11816 files\n",
      "  - Real: 19963 files\n",
      "Total files in release-in-the-wild dataset: 31779\n"
     ]
    }
   ],
   "source": [
    "# Function to count files in the dataset\n",
    "def count_files_in_dataset(base_dir, splits, labels):\n",
    "    file_counts = {}\n",
    "    total_files = 0\n",
    "\n",
    "    if splits:  # Structured splits (for-norm)\n",
    "        for split in splits:\n",
    "            split_counts = {}\n",
    "            for label in labels:\n",
    "                folder_path = os.path.join(base_dir, split, label)\n",
    "                if os.path.exists(folder_path):\n",
    "                    count = len([f for f in os.listdir(folder_path) if f.endswith(\".wav\")])\n",
    "                else:\n",
    "                    count = 0\n",
    "                split_counts[label] = count\n",
    "                total_files += count\n",
    "            file_counts[split] = split_counts\n",
    "    else:  # Structure of release-in-the-wild\n",
    "        for label in labels:\n",
    "            folder_path = os.path.join(base_dir, label)\n",
    "            if os.path.exists(folder_path):\n",
    "                count = len([f for f in os.listdir(folder_path) if f.endswith(\".wav\")])\n",
    "            else:\n",
    "                count = 0\n",
    "            file_counts[label] = count\n",
    "            total_files += count\n",
    "\n",
    "    return file_counts, total_files\n",
    "\n",
    "# Count files for both datasets\n",
    "for_norm_counts, for_norm_total = count_files_in_dataset(datasets[\"for-norm\"], splits, labels)\n",
    "release_in_wild_counts, release_in_wild_total = count_files_in_dataset(datasets[\"release-in-the-wild\"], None, labels)\n",
    "\n",
    "# Display counts\n",
    "print(\"For-Norm Dataset File Counts:\")\n",
    "for split, split_counts in for_norm_counts.items():\n",
    "    print(f\"{split.capitalize()}:\")\n",
    "    for label, count in split_counts.items():\n",
    "        print(f\"  - {label.capitalize()}: {count} files\")\n",
    "print(f\"Total files in for-norm dataset: {for_norm_total}\")\n",
    "\n",
    "print(\"\\nRelease-In-the-Wild Dataset File Counts:\")\n",
    "for label, count in release_in_wild_counts.items():\n",
    "    print(f\"  - {label.capitalize()}: {count} files\")\n",
    "print(f\"Total files in release-in-the-wild dataset: {release_in_wild_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from audio files\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        features = {\n",
    "            \"chroma_stft\": np.mean(librosa.feature.chroma_stft(y=y, sr=sr)),\n",
    "            \"rms\": np.mean(librosa.feature.rms(y=y)),\n",
    "            \"spectral_centroid\": np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
    "            \"spectral_bandwidth\": np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),\n",
    "            \"rolloff\": np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),\n",
    "            \"zero_crossing_rate\": np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "        }\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "        for i in range(1, 21):\n",
    "            features[f\"mfcc{i}\"] = np.mean(mfccs[i - 1])\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        with open(error_log, \"a\") as log_file:\n",
    "            log_file.write(f\"Error processing {file_path}: {e}\\n\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for-norm:  23%|██▎       | 16231/69300 [06:31<22:20, 39.60it/s] /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1891\n",
      "  warnings.warn(\n",
      "Processing for-norm:  39%|███▉      | 27260/69300 [13:11<29:51, 23.46it/s]  /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Processing for-norm:  40%|████      | 27856/69300 [13:39<36:41, 18.82it/s]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n",
      "Processing for-norm:  46%|████▋     | 32053/69300 [18:26<43:32, 14.26it/s]  /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1837\n",
      "  warnings.warn(\n",
      "Processing for-norm:  87%|████████▋ | 60339/69300 [44:56<06:42, 22.26it/s]  /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1690\n",
      "  warnings.warn(\n",
      "Processing for-norm: 100%|██████████| 69300/69300 [50:46<00:00, 22.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For-Norm features saved to: Processed_Features/for_norm_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction for for-norm dataset\n",
    "def process_audio_files_for_norm(base_dir):\n",
    "    all_features = []\n",
    "    total_files = sum(len(os.listdir(os.path.join(base_dir, split, label)))\n",
    "                      for split in splits\n",
    "                      for label in labels if os.path.exists(os.path.join(base_dir, split, label)))\n",
    "    progress_bar = tqdm(total=total_files, desc=\"Processing for-norm\")\n",
    "\n",
    "    for split in splits:\n",
    "        for label in labels:\n",
    "            folder_path = os.path.join(base_dir, split, label)\n",
    "            if not os.path.exists(folder_path):\n",
    "                continue\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(folder_path, file)\n",
    "                    features = extract_features(file_path)\n",
    "                    if features:\n",
    "                        features[\"filename\"] = file\n",
    "                        features[\"split\"] = split\n",
    "                        features[\"label\"] = label\n",
    "                        features[\"LABEL\"] = labels[label]\n",
    "                        all_features.append(features)\n",
    "                    progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "    return all_features\n",
    "\n",
    "# Run feature extraction\n",
    "for_norm_features = process_audio_files_for_norm(datasets[\"for-norm\"])\n",
    "for_norm_df = pd.DataFrame(for_norm_features)\n",
    "for_norm_csv = os.path.join(processed_output_dir, \"for_norm_features.csv\")\n",
    "for_norm_df.to_csv(for_norm_csv, index=False)\n",
    "print(f\"For-Norm features saved to: {for_norm_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing release-in-the-wild: 100%|██████████| 31779/31779 [32:39<00:00, 16.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Release-In-The-Wild features saved to: Processed_Features/release_in_wild_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction for release_in-the-wild (In the wild dataset)\n",
    "def process_audio_files_release_in_wild(base_dir):\n",
    "    all_features = []\n",
    "    total_files = sum(len(os.listdir(os.path.join(base_dir, label)))\n",
    "                      for label in labels if os.path.exists(os.path.join(base_dir, label)))\n",
    "    progress_bar = tqdm(total=total_files, desc=\"Processing release-in-the-wild\")\n",
    "\n",
    "    for label in labels:\n",
    "        folder_path = os.path.join(base_dir, label)\n",
    "        if not os.path.exists(folder_path):\n",
    "            continue\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                features = extract_features(file_path)\n",
    "                if features:\n",
    "                    features[\"filename\"] = file\n",
    "                    features[\"label\"] = label\n",
    "                    features[\"LABEL\"] = labels[label]\n",
    "                    all_features.append(features)\n",
    "                progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "    return all_features\n",
    "\n",
    "# Run feature extraction\n",
    "release_in_wild_features = process_audio_files_release_in_wild(datasets[\"release-in-the-wild\"])\n",
    "release_in_wild_df = pd.DataFrame(release_in_wild_features)\n",
    "release_in_wild_csv = os.path.join(processed_output_dir, \"release_in_wild_features.csv\")\n",
    "release_in_wild_df.to_csv(release_in_wild_csv, index=False)\n",
    "print(f\"Release-In-The-Wild features saved to: {release_in_wild_csv}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
